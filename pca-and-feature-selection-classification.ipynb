{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Comparing Feature Extraction and Classification Approaches\n**Introduction**\n\nIn this notebook, we are going to compare the performance and prediction accuracy of two classfication methods, Fisher's Linear Discriminant (LDA) and Naïve Bayes classifier, with two different feature extraction approaches, forward search and Priciple Component Analysis (PCA).\n\nA garment manufacturing operation dataset from UCI Machine Learning Repository was selected to predict worker productivity. Since, garment manufacturing is a labor-intensive operation, predicting productivity with feature extraction approaches allows the companies to keep track of the operational efficiency within factories and understand the factors affecting worker productivity. \n\nThere are 1197 data samples in this dataset of which the first 800 data was used for training and the remaining data is used for testing. Data description illustrates the attributes of the preprocessed data. For simplicity, only numeric data was used. This data is shown in number 7 – 14, inclusive.\n\n**Data Description**\n\n1. date: Date in MM-DD-YYYY\n2. quarter: A portion of the month. A month was divided into four quarters\n3. department: Associated department with the instance\n4. day: Day of the Week\n5. Team_no: Associated team number with the instance\n6. targeted_productivity: Targeted productivity set by the Authority for each team for each day.\n7. smw: Standard Minute Value, it is the allocated time for a task\n8. wip: Work in progress. Includes the number of unfinished items for products\n9. Over_time: Represents the amount of overtime by each team in minutes\n10. incentive: The amount of financial incentive (in BDT) that enables or motivates a particular course of action.\n11. Idle_time: The amount of time when the production was interrupted due to several reasons\n12. Idle_men: The number of workers who were idle due to production interruption\n13. no_of_style_change: Number of changes in the style of a particular product\n14. No_of_workers: Number of workers in each team\n15. actual_productivity: The actual % of productivity that was delivered by the workers. It ranges from 0-1","metadata":{}},{"cell_type":"code","source":"# Importing relevant libraries\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\n# imports for plotting results\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # Used to plot the confusion matrix as a heat map. Need to install not on computer.\n\nimport time\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.147900Z","iopub.execute_input":"2022-01-18T19:59:45.148212Z","iopub.status.idle":"2022-01-18T19:59:45.153906Z","shell.execute_reply.started":"2022-01-18T19:59:45.148174Z","shell.execute_reply":"2022-01-18T19:59:45.152791Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing**\n\nTo facilitate the classification, data preprocessing was performed. First, attributes with non-numeric value (Attribute 1 to 6) are removed. Missing values in the attribute of wip (Work in progress), which indicates the number of unfinished products, were then filled with 0.\n\n","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/productivity-prediction-of-garment-employees/garments_worker_productivity.csv\")  # Import data\nprint(data.head())\ndata = data.fillna(0)  # Fills N/A values with zeroes\ndata = data.values  # Converting data to a numpy representation of the dataframe","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.155205Z","iopub.execute_input":"2022-01-18T19:59:45.155708Z","iopub.status.idle":"2022-01-18T19:59:45.186258Z","shell.execute_reply.started":"2022-01-18T19:59:45.155676Z","shell.execute_reply":"2022-01-18T19:59:45.185290Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\nx_raw = data[:, 6:-1]\nx_raw = np.array(x_raw, dtype=float)\nx_train = x_raw[:800, :]  # First 800 rows used for training\nx_test = x_raw[800:, :]  # Remainder of the rows used for testing","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.187576Z","iopub.execute_input":"2022-01-18T19:59:45.188351Z","iopub.status.idle":"2022-01-18T19:59:45.194420Z","shell.execute_reply.started":"2022-01-18T19:59:45.188307Z","shell.execute_reply":"2022-01-18T19:59:45.193620Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"For the analysis, the column representing attributes of the actual percentage of worker productivity in the original data was replaced with a column containing binary values (1,0) where 1 represents a point when the actual productivity is larger than the targeted productivity, and 0 otherwise. I.e., 0=does not meet productivity, 1=meets productivity.","metadata":{}},{"cell_type":"code","source":"def class_input_data(xc):\n    for i in range(len(xc)):\n        if xc[i] > data[i, 5]:\n            xc[i] = 1\n        else:\n            xc[i] = 0\n    return xc","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.196523Z","iopub.execute_input":"2022-01-18T19:59:45.196813Z","iopub.status.idle":"2022-01-18T19:59:45.206924Z","shell.execute_reply.started":"2022-01-18T19:59:45.196771Z","shell.execute_reply":"2022-01-18T19:59:45.206193Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Classifying data based on whether the workers meet productivity (assigned 1) or not (assigned 0)\nxc = data[:, -1:]\nxc = np.array(xc, dtype=float).ravel()\n\nxc_train = data[:800, -1:]  # actual productivity of the first 800 rows\nxc_train = np.array(xc_train, dtype=float).ravel()\n\nxc_test = data[800:, -1:]  # actual productivity values of the last 397 rows\nxc_test = np.array(xc_test, dtype=float).ravel()\n\nxc = class_input_data(xc)\nxc_train = class_input_data(xc_train)\nxc_test = class_input_data(xc_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.208449Z","iopub.execute_input":"2022-01-18T19:59:45.208963Z","iopub.status.idle":"2022-01-18T19:59:45.220853Z","shell.execute_reply.started":"2022-01-18T19:59:45.208920Z","shell.execute_reply":"2022-01-18T19:59:45.219982Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"**Classification**\n\nFisher’s Linear Discriminant (FLD) classification, referred to as LDA within, and Naive Bayes classification were applied to the dataset after extracting key features using PCA and Feature Selection methods. Training time and testing time are recorded for comparison.","metadata":{}},{"cell_type":"code","source":"def LDA_prediction(training_data, target_training_class, input_data):\n    lda = LinearDiscriminantAnalysis()\n\n    # Training\n    start_time = time.time()\n    lda.fit(training_data, target_training_class)\n    end_time = time.time()\n    training_time = end_time - start_time\n\n    # Testing\n    start_time = time.time()\n    prediction = lda.predict(input_data)\n    end_time = time.time()\n    testing_time = end_time - start_time\n    return prediction, training_time, testing_time","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.222293Z","iopub.execute_input":"2022-01-18T19:59:45.222524Z","iopub.status.idle":"2022-01-18T19:59:45.235225Z","shell.execute_reply.started":"2022-01-18T19:59:45.222495Z","shell.execute_reply":"2022-01-18T19:59:45.234380Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes Classifier\ndef naive_bayes_prediction(training_data, target_training_class, input_data):\n    clf = GaussianNB()\n\n    # Training\n    start_time = time.time()\n    clf.fit(training_data, target_training_class)\n    end_time = time.time()\n    training_time = end_time - start_time\n\n    # Testing\n    start_time = time.time()\n    prediction = clf.predict(input_data)\n    end_time = time.time()\n    testing_time = end_time - start_time\n\n    return prediction, training_time, testing_time","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.236939Z","iopub.execute_input":"2022-01-18T19:59:45.237530Z","iopub.status.idle":"2022-01-18T19:59:45.245637Z","shell.execute_reply.started":"2022-01-18T19:59:45.237486Z","shell.execute_reply":"2022-01-18T19:59:45.244957Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**\n\nA confusion matrix function was created to plot the results of the prediction and return the accuracy. This matrix shows the True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (NP) results. ","metadata":{}},{"cell_type":"code","source":"# Plotting confusion matrix\ndef confusion_matrix_results(actual_results, predicted_results):\n    matrix = confusion_matrix(actual_results, predicted_results, labels=[1.0, 0.0])\n    print(\"Classification report is as follows:\")\n    print(\"\")\n    print(classification_report(actual_results, predicted_results, labels=[1.0, 0.0]))\n\n    # Derivations from the confusion matrix. True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN)\n    TP, FN, FP, TN = confusion_matrix(actual_results, predicted_results, labels=[1.0, 0.0]).ravel()\n\n    TPR = round((TP / (TP + FN)) * 100, 1)  # True positive rate (how often it predicts 'yes' when it's 'yes')\n    TNR = round((TN / (TN + FP)) * 100, 1)  # True negative rate (how often it predicts 'no' when it's 'no')\n    PPV = round((TP / (TP + FP)) * 100,\n                1)  # precision or positive prediction value (how hoften is it correct when it predicts 'yes')\n    NPV = round((TN / (TN + FN)) * 100, 1)  # Negative prediction value\n    FPR = round((FP / (FP + TN)) * 100, 1)  # False positive rate (how often it predicts 'yes' when it's 'no')\n    FNR = round((FN / (TP + FN)) * 100, 1)  # False negative rate (how often it predicts 'no' when it's 'yes')\n    FDR = round((FP / (TP + FP)) * 100, 1)  # False discovery rate\n    accuracy = round(((TP + TN) / (TP + FP + FN + TN)) * 100, 1)  # how often is the classifier right\n    # Note: Values above converted to percentages\n\n    rates_matrix = [[TPR, FNR], [FPR, TNR]]  # results of the confusion matrix as percetages of the statistical rates\n    statistical_matrix = [[TPR, FNR], [TNR, FPR]]  # results of the confusion matrix arranged as TPR and FPR\n\n    # Heatmap plot\n    # Results of the confusion matrix\n\n    plt.rc('font', size=20)  # controls default text size\n    plt.rc('axes', titlesize=20)  # fontsize of the title\n    plt.rc('axes', labelsize=20)  # fontsize of the x and y labels\n    plt.rc('xtick', labelsize=20)  # fontsize of the x tick labels\n    plt.rc('ytick', labelsize=20)  # fontsize of the y tick labels\n    plt.rc('legend', fontsize=20)  # fontsize of the legend\n\n    # Heatmap plot\n    # Results of the confusion matrix\n    plot1 = plt.figure()  # first plot showing confusion matrix observations\n    g1 = sns.heatmap(matrix, annot=True, cmap='Blues', fmt='g', square=True)\n    g1.set_title('Confusion Matrix of the Number of Observations \\n Using 5 Principal Components or Features',\n                 weight='bold')\n    g1.set_xlabel('Predicted Values')\n    g1.set_ylabel('Actual Values')\n\n    g1.xaxis.set_ticklabels(['1', '0'])\n    g1.yaxis.set_ticklabels(['1', '0'])\n    # Plotting the statistical results of the confusion matrix\n    f, (ax1, ax2) = plt.subplots(1, 2, sharey=False,\n                                 figsize=(11, 4))  # second plot showing confusion matrix results as percentages\n\n    g2 = sns.heatmap(rates_matrix, annot=True, cmap='Blues', fmt='g', ax=ax1, cbar=False, square=True)\n    for t in g2.texts: t.set_text(\n        t.get_text() + \" %\")  # adding a percentage symbol to the plot by iterating over the results\n    g2.xaxis.set_ticklabels(['1', '0'])\n    g2.yaxis.set_ticklabels(['1', '0'])\n\n    g3 = sns.heatmap(statistical_matrix, annot=True, cmap='Blues', fmt='g', ax=ax2, square=True)\n    for t in g3.texts: t.set_text(\n        t.get_text() + \" %\")  # adding a percentage symbol to the plot by iterating over the results\n    g3.xaxis.set_ticklabels(['TPR', 'FNR'])\n    g3.yaxis.set_ticks([])\n\n    f.suptitle('Confusion Matrix Results and TPR and FNR as Percentages',\n               weight='bold')\n    f.text(0.5, 0.04, 'Predicted Values', ha='center')\n    f.text(0.04, 0.5, 'Actual Values', va='center', rotation='vertical')\n\n    plt.show()\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.248157Z","iopub.execute_input":"2022-01-18T19:59:45.248552Z","iopub.status.idle":"2022-01-18T19:59:45.264500Z","shell.execute_reply.started":"2022-01-18T19:59:45.248508Z","shell.execute_reply":"2022-01-18T19:59:45.263813Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**Principle Component Analysis (PCA)**\n\nFor PCA, the selected data was split into training and testing data with 800 datasets for training and 397 datasets for testing. Eigenvectors and Eigenvalues of the training dataset were calculated within the PCA function, and the principal components determined resulting in a reduced matrix containing the principal scores. These scores were input into the LDA classifier function along with the testing data. The resulting output was the classes of the testing data and the time it took to train and test the datasets using an LDA classifier. Similarly, these principal scores were input in the Naïve Bayes classifier function. The resulting output was the classes of the testing data and the time it took to train and test the datasets. Results were also plotted on a confusion matrix and accuracy using the different classifiers presented.","metadata":{}},{"cell_type":"code","source":"# pca function\ndef pca(raw_data, actual_training_class, actual_testing_class):\n    # Principal Component Analysis\n    x_mean = np.mean(raw_data, axis=0)\n    x_mc = (raw_data - x_mean)\n    x_cov = np.dot(x_mc.T, x_mc)\n    D, E = np.linalg.eig(x_cov)  # Eigenvalues and corresponding eigenvectors\n\n    # Sorting the eigenvalues and eigenvectors\n    sorted_index = np.argsort(D)\n    sorted_D = D[sorted_index]\n    sorted_E = np.zeros((8, 8))\n    index = 0\n    for i in range(7, -1, -1):\n        sorted_E[:, index] = E[:, sorted_index[i]]\n        index = index + 1\n\n    y = np.dot(x_mc, sorted_E)  # principal component outputs i.e. all principal component scores\n\n    # Based on visual inspection, we shall keep features the first five features since\n    # the eigenvalues are significantly large for those features.\n\n    reduced_E = sorted_E[:, 0:5]  # reduced eigenvectors\n    reduced_y = y[:, 0:5]  # reduced principal component outputs\n\n    y_train = reduced_y[:800, :]\n    y_test = reduced_y[800:, :]\n\n    # Predicting outputs with LDA and Naive Bayes classifiers\n    predicted_results_LDA, training_time_LDA, testing_time_LDA = LDA_prediction(y_train, actual_training_class, y_test)\n\n    predicted_results_NB, training_time_NB, testing_time_NB = naive_bayes_prediction(y_train, actual_training_class,\n                                                                                     y_test)\n\n    # Confusion matrix and accuracy of the results using the different classifiers\n    print('--- LDA Result ---\\n')\n    LDA_testing_accuracy = confusion_matrix_results(actual_testing_class,\n                                                    predicted_results_LDA)  # Accuracy of the classifier as a percetage\n    print('\\n--- NB Result ---\\n')\n    NB_testing_accuracy = confusion_matrix_results(actual_testing_class,\n                                                   predicted_results_NB)  # Accuracy of the classifier as a percetage\n\n    return training_time_LDA, testing_time_LDA, LDA_testing_accuracy, training_time_NB, testing_time_NB, NB_testing_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.265686Z","iopub.execute_input":"2022-01-18T19:59:45.266090Z","iopub.status.idle":"2022-01-18T19:59:45.280615Z","shell.execute_reply.started":"2022-01-18T19:59:45.266051Z","shell.execute_reply":"2022-01-18T19:59:45.279814Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**Feature Selection**\n\nA forward search Feature Selection method was performed. Since 5 key attributes were used during PCA, our forward search method also extracted the 5 most significant attributes for analysis. A zero matrix was created and filled with the best features at the end of the function. These features were input into the LDA classifier and Naïve Bayes classifier functions with 800 datasets representing the training dataset and 397 representing the testing dataset. The resulting outputs were the class of the testing data and the time it took to train and test the datasets using the different classifiers.","metadata":{}},{"cell_type":"code","source":"# Feature selection (SFS)\ndef feature_selection(input_data, data_classes):\n    selected_features = 5  # Using five because that is what was found to be the best with pca\n    total_features = 8\n    best_feature = 1000 * np.ones(selected_features)  # creating a list of 100's that represents the best five features.\n\n    # Determine the best features. Must use the raw data\n    for i in range(selected_features):\n        # Create an array of zeros that will contain the five best features\n        if i == 0:\n            x_selection = np.zeros((input_data.shape[0], 1))\n        else:\n            x_selection = np.concatenate((x_selection, np.zeros((input_data.shape[0], 1))), axis=1)\n\n        error = 10000 * np.ones(total_features)\n        # Loop through the created array and add the best features from the raw data\n\n        for j in range(total_features):\n            # check if the feature 'j' has not been used\n            if (not (j == best_feature[0] or j == best_feature[1]\n                     or j == best_feature[2] or j == best_feature[3] or j == best_feature[4])):\n                x_selection[:, i] = input_data[:, j]  # add the feature to the selection\n\n                prediction, training_time_LDA, testing_time_LDA = LDA_prediction(x_selection, data_classes,\n                                                                                 x_selection)  # Results were the same for naive bayes classifier so opted to use LDA.\n                error[j] = sum(abs(prediction != data_classes))\n\n        best_feature[i] = np.argmin(error)\n        x_selection[:, i] = input_data[:, int(best_feature[i])]\n\n    # Train the results using the best features from above. Data is split between training and testing\n    x_selection_training = x_selection[:800, :]\n    x_selection_testing = x_selection[800:, :]\n\n    testing_class = data_classes[800:]\n    training_class = data_classes[0:800]\n    \n    predicted_results_LDA, training_time_LDA, testing_time_LDA = LDA_prediction(x_selection_training, training_class,\n                                                                                x_selection_testing)\n    \n    predicted_results_NB, training_time_NB, testing_time_NB = naive_bayes_prediction(x_selection_training,\n                                                                                     training_class,\n                                                                                     x_selection_testing)\n    \n    print(\"--- LDA Result ---\\n\")\n    LDA_testing_accuracy = confusion_matrix_results(testing_class, predicted_results_LDA)\n    end_time = time.time()\n    LDA_error = sum(predicted_results_LDA != testing_class)\n    \n    print(\"\\n--- NB Result ---\\n\")\n    NB_testing_accuracy = confusion_matrix_results(testing_class, predicted_results_NB)\n    NB_error = sum(predicted_results_NB != testing_class)\n    return training_time_LDA, testing_time_LDA, LDA_testing_accuracy, training_time_NB, testing_time_NB, NB_testing_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.281818Z","iopub.execute_input":"2022-01-18T19:59:45.282157Z","iopub.status.idle":"2022-01-18T19:59:45.297810Z","shell.execute_reply.started":"2022-01-18T19:59:45.282115Z","shell.execute_reply":"2022-01-18T19:59:45.296968Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Classification Result**\n\nThe codes below print the result of the two classifications with PCA and feature selection.","metadata":{}},{"cell_type":"code","source":"# PCA\nLDA_training_time_pca, LDA_testing_time_pca, LDA_accuracy_pca, NB_training_time_pca, NB_testing_time_pca, NB_accuracy_pca = pca(\n    x_raw, xc_train, xc_test)\nprint(\"--- PCA-LDA Result ---\")\nprint(\"Training time: \", \"{:.2e}\".format(LDA_training_time_pca), \"s\")\nprint(\"Testing time: \", \"{:.2e}\".format(LDA_testing_time_pca), \"s\")\nprint(\"Total computational time: \",\n      \"{:.2e}\".format(LDA_training_time_pca + LDA_testing_time_pca), \"s\")\nprint(\"Prediction accuracy: \", LDA_accuracy_pca, \"%\")\nprint(\"\")\nprint(\"--- PCA-NB Result ---\")\nprint(\"Training time: \", \"{:.2e}\".format(NB_training_time_pca), \"s\")\nprint(\"Testing time: \", \"{:.2e}\".format(NB_testing_time_pca), \"s\")\nprint(\"Total computational time: \",\n      \"{:.2e}\".format(NB_training_time_pca + NB_testing_time_pca), \"s\")\nprint(\"Prediction accuracy: \", NB_accuracy_pca, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:45.299041Z","iopub.execute_input":"2022-01-18T19:59:45.299377Z","iopub.status.idle":"2022-01-18T19:59:46.341763Z","shell.execute_reply.started":"2022-01-18T19:59:45.299320Z","shell.execute_reply":"2022-01-18T19:59:46.340909Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Feature Selection\nLDA_training_time_fs, LDA_testing_time_fs, LDA_accuracy_fs, NB_training_time_fs, NB_testing_time_fs, NB_accuracy_fs = feature_selection(\n    x_raw, xc)\nprint(\"--- FS-LDA Result ---\")\nprint(\"Training time: \", \"{:.2e}\".format(LDA_training_time_fs), \"s\")\nprint(\"Testing time: \", \"{:.2e}\".format(LDA_testing_time_fs), \"s\")\nprint(\"Total computational time: \",\n      \"{:.2e}\".format(LDA_training_time_fs + LDA_testing_time_fs), \"s\")\nprint(\"Prediction accuracy: \", LDA_accuracy_fs, \"%\")\nprint(\"\")\nprint(\"--- FS-NB Result ---\")\nprint(\"Training time: \",\n      \"{:.2e}\".format(NB_training_time_fs), \"s\")\nprint(\"Testing time: \",\n      \"{:.2e}\".format(NB_testing_time_fs), \"s\")\nprint(\"Total computational time: \",\n      \"{:.2e}\".format(NB_training_time_fs + NB_testing_time_fs), \"s\")\nprint(\"Prediction accuracy: \", NB_accuracy_fs, \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-01-18T19:59:46.345105Z","iopub.execute_input":"2022-01-18T19:59:46.345337Z","iopub.status.idle":"2022-01-18T19:59:47.658709Z","shell.execute_reply.started":"2022-01-18T19:59:46.345307Z","shell.execute_reply":"2022-01-18T19:59:47.657851Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"**Discussions**\n\nBased on the results, Feature Selection using LDA, and Naïve Bayes classifier, had the most accuracy in the prediction with a prediction accuracy of 70.0%. The classification accuracy for PCA (54.9% using LDA and 51.9% using Naïve Bayes) was lower than that with feature selection. One reason that may have led to this result was that PCA assumed that the attributes with highest variances contained the most important information about the data, however, this may not always be true. In contrast, feature selection trained and tested each attributes selecting features that resulted in the least number of errors when classified. As a result, the accuracy using feature selection was higher than that using PCA. \n\nMoreover, computation time for using PCA scores and key features from feature selection was similar for the naïve bayes classifier however, it took longer to classify the testing data using the LDA classifier for PCA scores than for feature selected key features. This could have been due to the computation of large numbers since the scores represent that largest Eigenvalues and corresponding Eigenvectors.\n\nLastly, regardless of the method, PCA vs Feature Selection, there was a large portion of Type I errors identified during classification meaning that most testing data are falsely predicted as 1 (being productive), while it was the opposite.\nThis could have been due to selecting a dataset with a significant amount of missing data in some of the attributes. Some of the missing information, although replaced with zero, was most likely not zero. As a result, the predictions were\nnegatively impacted.","metadata":{}}]}